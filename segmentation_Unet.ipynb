{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_file(zip_filename, output_dir):\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zipf:\n",
        "        zipf.extractall(output_dir)\n",
        "    print(f\"Files extracted to {output_dir}\")\n",
        "\n",
        "# Example usage:\n",
        "unzip_file('/content/Cells.zip', '/content/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f_2woGQTf08",
        "outputId": "c0c8a129-8be9-475b-b1ee-611747f2f9e8"
      },
      "id": "1f_2woGQTf08",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "\n",
        "def augment_and_save_images_with_masks(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, total_samples=2000):\n",
        "    # Define augmentations with resizing to 256x256\n",
        "    transform = A.Compose([\n",
        "        #A.Resize(256, 256, always_apply=True),  # Resize both images & masks to 256x256\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=30, p=0.5),\n",
        "        #A.RandomCrop(height=256, width=256, p=0.5),  # Crop within 256x256\n",
        "    ])\n",
        "\n",
        "    # Get list of image and mask files\n",
        "    image_files = sorted([f for f in os.listdir(input_image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    mask_files = sorted([f for f in os.listdir(input_mask_folder) if f.lower().endswith(('.jpeg'))])\n",
        "\n",
        "    # Ensure image-mask alignment\n",
        "    if len(image_files) != len(mask_files):\n",
        "        print(\"Warning: Mismatch in the number of images and masks!\")\n",
        "\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(output_image_folder, exist_ok=True)\n",
        "    os.makedirs(output_mask_folder, exist_ok=True)\n",
        "\n",
        "    num_original_images = len(image_files)\n",
        "\n",
        "    # Determine augmentations per image needed\n",
        "    num_augs_per_image = max(1, total_samples // num_original_images)\n",
        "\n",
        "    index = 0\n",
        "    for img_name, mask_name in tqdm(zip(image_files, mask_files), total=num_original_images):\n",
        "        image_file = os.path.join(input_image_folder, img_name)\n",
        "        mask_file = os.path.join(input_mask_folder, mask_name)\n",
        "\n",
        "        # Load image in RGB\n",
        "        image = cv2.imread(image_file)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "        # Load mask in RGB (preserve colors)\n",
        "        mask = cv2.imread(mask_file, cv2.IMREAD_UNCHANGED)  # Load mask in original color (not grayscale)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)  # Ensure it's RGB\n",
        "\n",
        "        # Skip invalid images/masks\n",
        "        if image is None or mask is None:\n",
        "            print(f\"Skipping: {img_name} (image/mask not found or invalid)\")\n",
        "            continue\n",
        "\n",
        "        # Resize both to 256x256\n",
        "        #image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
        "        #mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)  # Use NEAREST to preserve segmentation colors\n",
        "\n",
        "        for _ in range(num_augs_per_image):\n",
        "            augmented = transform(image=image, mask=mask)\n",
        "            augmented_image = augmented['image']\n",
        "            augmented_mask = augmented['mask']\n",
        "\n",
        "            # Ensure valid augmented images/masks\n",
        "            if augmented_image is None or augmented_mask is None:\n",
        "                continue\n",
        "\n",
        "            # Save augmented image and mask\n",
        "            output_image_file = os.path.join(output_image_folder, f\"augmented_{index}.jpg\")\n",
        "            output_mask_file = os.path.join(output_mask_folder, f\"augmented_{index}.jpeg\")\n",
        "\n",
        "            cv2.imwrite(output_image_file, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))  # Convert back to BGR for OpenCV\n",
        "            cv2.imwrite(output_mask_file, cv2.cvtColor(augmented_mask, cv2.COLOR_RGB2BGR))  # Ensure mask remains in RGB\n",
        "\n",
        "            index += 1\n",
        "            if index >= total_samples:\n",
        "                break  # Stop when we reach the desired number of samples\n",
        "\n",
        "        if index >= total_samples:\n",
        "            break  # Stop if we have reached 2000 samples\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define paths\n",
        "    input_image_folder = \"/content/Cells/Train/images/\"\n",
        "    input_mask_folder = \"/content/Cells/Train/masks/\"\n",
        "    output_image_folder = \"/content/cell_bi/aug_images_bi/\"\n",
        "    output_mask_folder = \"/content/cell_bi/aug_masks_bi/\"\n",
        "\n",
        "    # Set total number of augmented image-mask pairs\n",
        "    total_samples = 5000\n",
        "\n",
        "    # Run augmentation\n",
        "    augment_and_save_images_with_masks(input_image_folder, input_mask_folder, output_image_folder, output_mask_folder, total_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU5DItZSxfNI",
        "outputId": "a0c7deb3-6d56-44f9-db20-6f86f6da2987"
      },
      "id": "SU5DItZSxfNI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0da01f6"
      },
      "outputs": [],
      "source": [
        "IMG_ROWS = 256\n",
        "IMG_COLS = 256"
      ],
      "id": "d0da01f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2ec6738"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import imageio\n",
        "from scipy import ndimage\n",
        "from glob import glob\n",
        "import zipfile\n",
        "#import tensorflow as tf"
      ],
      "id": "b2ec6738"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63e2f550"
      },
      "outputs": [],
      "source": [
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../content/\"]).decode(\"utf8\"))"
      ],
      "id": "63e2f550"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3376393"
      },
      "outputs": [],
      "source": [
        "train_img_paths = sorted(glob('../content/cell_bi/aug_images_bi/*.jpg'))\n",
        "train_mask_paths = sorted(glob('../content/cell_bi/aug_masks_bi/*.jpeg'))"
      ],
      "id": "f3376393"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb9zm6yhzCBa"
      },
      "outputs": [],
      "source": [
        "test_img_paths = sorted(glob('../content/Cells/test/test_images/*.JPG'))\n",
        "test_mask_paths = sorted(glob('../content/Cells/test/test_masks/*.jpeg'))"
      ],
      "id": "tb9zm6yhzCBa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4663b10"
      },
      "outputs": [],
      "source": [
        "train_imgs = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n",
        "                        for path in train_img_paths])\n",
        "\n",
        "train_masks = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n",
        "                        for path in train_mask_paths])\n",
        "\n",
        "train_masks = train_masks.astype(np.float32)\n",
        "train_masks[train_masks<=127] = 0.\n",
        "train_masks[train_masks>127] = 1.\n",
        "train_masks = np.reshape(train_masks, (*train_masks.shape, 1))"
      ],
      "id": "a4663b10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQevH9wTzJgb"
      },
      "outputs": [],
      "source": [
        "test_imgs = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n",
        "                        for path in test_img_paths])\n",
        "\n",
        "test_masks = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n",
        "                        for path in test_mask_paths])\n",
        "\n",
        "test_masks = test_masks.astype(np.float32)\n",
        "test_masks[test_masks<=127] = 0.\n",
        "test_masks[test_masks>127] = 1.\n",
        "test_masks = np.reshape(test_masks, (*test_masks.shape, 1))"
      ],
      "id": "dQevH9wTzJgb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKlmVEj_zfar"
      },
      "source": [
        "# Train Image"
      ],
      "id": "kKlmVEj_zfar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed12e930"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "fig = plt.figure(0, figsize=(200, 200))\n",
        "fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(train_imgs[0])\n",
        "fig.add_subplot(1, 2, 2)\n",
        "plt.imshow(np.squeeze(train_masks[0]), cmap='gray')"
      ],
      "id": "ed12e930"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRTGtVmbzsmr"
      },
      "source": [
        "# Test image"
      ],
      "id": "qRTGtVmbzsmr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axsPOnxvzxZD"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "fig = plt.figure(0, figsize=(20, 20))\n",
        "fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(test_imgs[0])\n",
        "fig.add_subplot(1, 2, 2)\n",
        "plt.imshow(np.squeeze(test_masks[0]), cmap='gray')"
      ],
      "id": "axsPOnxvzxZD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtA9y3WOz8uK"
      },
      "source": [
        "# Model"
      ],
      "id": "gtA9y3WOz8uK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ae68a26"
      },
      "outputs": [],
      "source": [
        "!pip3 install -U segmentation-models\n",
        "%env SM_FRAMEWORK=tf.keras\n",
        "import segmentation_models as sm\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.set_image_data_format('channels_last')"
      ],
      "id": "7ae68a26"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99568e69"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "#create model\n",
        "# binary segmentation (this parameters are default when you call Unet('resnet34')\n",
        "model = sm.Unet('vgg19', classes=1, activation='sigmoid')\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "dice_loss = sm.losses.dice_loss\n",
        "model.compile(optimizer=optimizer, loss=dice_loss, metrics=['accuracy'])\n"
      ],
      "id": "99568e69"
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models as sm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create the basic Unet model (without any backbone)\n",
        "model = sm.Unet(input_shape=(256, 256, 3), classes=1, activation='sigmoid', encoder_weights=None)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Define the loss function (Dice loss from segmentation_models)\n",
        "dice_loss = sm.losses.dice_loss\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=dice_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "e3i-JVKbgrzO"
      },
      "id": "e3i-JVKbgrzO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models as sm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Create the basic Unet model (without any backbone)\n",
        "model = sm.Unet(input_shape=(256, 256, 3), classes=1, activation='sigmoid', encoder_weights=None)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Define the loss function (Dice loss from segmentation_models)\n",
        "dice_loss = sm.losses.dice_loss\n",
        "\n",
        "# Define the Dice Coefficient metric\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Compile the model with Dice Coefficient as a metric\n",
        "model.compile(optimizer=optimizer, loss=dice_loss, metrics=['accuracy', dice_coefficient])\n"
      ],
      "metadata": {
        "id": "uE5t8_Yrn_8w"
      },
      "id": "uE5t8_Yrn_8w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52b4faac"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ],
      "id": "52b4faac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad6de410"
      },
      "source": [
        "## Set the loss function"
      ],
      "id": "ad6de410"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP3PP5UWGWai"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming you have defined the 'model', 'train_imgs', and 'train_masks'\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=1000, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    train_imgs[50:],\n",
        "    train_masks[50:],\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    validation_data=(\n",
        "        train_imgs[:1],\n",
        "        train_masks[:1]\n",
        "    ),\n",
        "    callbacks=[early_stopping]  # Add the early stopping callback\n",
        ")\n"
      ],
      "id": "wP3PP5UWGWai"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a79957ed"
      },
      "source": [
        "## Предсказание модели"
      ],
      "id": "a79957ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRJoGlvPschi"
      },
      "outputs": [],
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "fRJoGlvPschi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j3p1vCGstrU"
      },
      "outputs": [],
      "source": [
        "# Plot training accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "8j3p1vCGstrU"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_index = 2\n",
        "\n",
        "# Get the test image and mask\n",
        "test_image = test_imgs[test_index]\n",
        "ground_truth_mask = test_masks[test_index]\n",
        "\n",
        "# Squeeze the ground_truth_mask to remove the extra dimension\n",
        "ground_truth_mask = ground_truth_mask.squeeze()\n",
        "\n",
        "# Predict the mask using the trained model\n",
        "predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
        "\n",
        "# Plot the test image, ground truth mask, and predicted mask\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.imshow(test_image)\n",
        "plt.title('Test Image')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.imshow(ground_truth_mask, cmap='gray')\n",
        "plt.title('Ground Truth Mask')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.imshow(predicted_mask, cmap='gray')\n",
        "plt.title('Predicted Mask')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h-xpblJwAwim"
      },
      "id": "h-xpblJwAwim",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJLWKS5UQmAo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_index = 6\n",
        "\n",
        "# Get the test image and mask\n",
        "test_image = test_imgs[test_index]\n",
        "ground_truth_mask = test_masks[test_index]\n",
        "\n",
        "# Squeeze the ground_truth_mask to remove the extra dimension\n",
        "ground_truth_mask = ground_truth_mask.squeeze()\n",
        "\n",
        "# Predict the mask using the trained model\n",
        "predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
        "\n",
        "# Plot the test image, ground truth mask, and predicted mask\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.imshow(test_image)\n",
        "plt.title('Test Image')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.imshow(ground_truth_mask, cmap='gray')\n",
        "plt.title('Ground Truth Mask')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.imshow(predicted_mask, cmap='gray')\n",
        "plt.title('Predicted Mask')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "CJLWKS5UQmAo"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_index = 1\n",
        "\n",
        "# Get the test image and mask\n",
        "test_image = test_imgs[test_index]\n",
        "ground_truth_mask = test_masks[test_index]\n",
        "\n",
        "# Squeeze the ground_truth_mask to remove the extra dimension\n",
        "ground_truth_mask = ground_truth_mask.squeeze()\n",
        "\n",
        "# Predict the mask using the trained model\n",
        "predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
        "\n",
        "# Plot the test image, ground truth mask, and predicted mask\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.imshow(test_image)\n",
        "plt.title('Test Image')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.imshow(ground_truth_mask, cmap='gray')\n",
        "plt.title('Ground Truth Mask')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.imshow(predicted_mask, cmap='gray')\n",
        "plt.title('Predicted Mask')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kX1c5lEZ_2Tp"
      },
      "id": "kX1c5lEZ_2Tp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dys-hZdGQpX2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "test_index = 1\n",
        "\n",
        "# Get the test image and mask\n",
        "test_image = test_imgs[test_index]\n",
        "ground_truth_mask = test_masks[test_index]\n",
        "\n",
        "# Predict the mask using the trained model\n",
        "predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
        "\n",
        "# Plot the test image, ground truth mask, and predicted mask\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Test Image\n",
        "plt.subplot(131)\n",
        "plt.imshow(test_image)\n",
        "plt.title('Test Image')\n",
        "\n",
        "# Ground Truth Mask - Squeeze it if needed\n",
        "ground_truth_mask = np.squeeze(ground_truth_mask)  # Remove any (1) dims\n",
        "plt.subplot(132)\n",
        "plt.imshow(ground_truth_mask, cmap='gray')\n",
        "plt.title('Ground Truth Mask')\n",
        "\n",
        "# Predicted Mask - Squeeze it if needed\n",
        "predicted_mask = np.squeeze(predicted_mask)  # Remove any (1) dims\n",
        "plt.subplot(133)\n",
        "plt.imshow(predicted_mask, cmap='gray')\n",
        "plt.title('Predicted Mask')\n",
        "\n",
        "plt.show()\n"
      ],
      "id": "Dys-hZdGQpX2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3RZ0hrn8ovi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Assuming you have defined and trained the 'model'\n",
        "# model = ...\n",
        "\n",
        "# Save the trained model to an HDF5 file in your Google Drive\n",
        "save_model(model, '/content/segmentation_model_unetCELLS.h5')\n",
        "\n",
        "print(\"Model saved as 'segmentation_model.h5'\")\n"
      ],
      "id": "H3RZ0hrn8ovi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLWlfFJxPSdY"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_imgs, test_masks, batch_size=1)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "id": "wLWlfFJxPSdY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C-LIpsBPZjn"
      },
      "outputs": [],
      "source": [
        "train_loss, train_accuracy = model.evaluate(train_imgs, train_masks, batch_size=1)\n",
        "\n",
        "print(\"Train Loss:\", train_loss)\n",
        "print(\"Train Accuracy:\", train_accuracy)"
      ],
      "id": "_C-LIpsBPZjn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1f70967"
      },
      "outputs": [],
      "source": [
        "test_paths = sorted(glob('../content/drive/MyDrive/Segmentation/FinalDatasetThesis/val/*.png'))"
      ],
      "id": "c1f70967"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b06dc8b"
      },
      "source": [
        "def test_img_generator(test_paths):\n",
        "    while True:\n",
        "        for path in test_paths:\n",
        "            yield np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))])"
      ],
      "id": "5b06dc8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "989cd79e"
      },
      "source": [
        "pred = model.predict_generator(test_img_generator(test_paths[:10]), len(test_paths[:10]))"
      ],
      "id": "989cd79e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d79da108"
      },
      "source": [
        "## Визуализируем результат"
      ],
      "id": "d79da108"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abef5150"
      },
      "source": [
        "fig = plt.figure(0, figsize=(20, 10))\n",
        "k = 5\n",
        "fig.add_subplot(2, 2, 1)\n",
        "plt.imshow(imageio.imread(test_paths[k]))\n",
        "fig.add_subplot(2, 2, 2)\n",
        "plt.imshow(np.squeeze(cv2.resize(pred[k], (TEST_IMG_ROWS, TEST_IMG_COLS))), cmap='gray')\n",
        "fig.add_subplot(2, 2, 3)\n",
        "plt.imshow(imageio.imread(test_paths[k+1]))\n",
        "fig.add_subplot(2, 2, 4)\n",
        "plt.imshow(np.squeeze(cv2.resize(pred[k+1], (TEST_IMG_ROWS, TEST_IMG_COLS))), cmap='gray')"
      ],
      "id": "abef5150"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8247202d"
      },
      "source": [
        "## Подготавливаем данные для отправки"
      ],
      "id": "8247202d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f75d84c3"
      },
      "outputs": [],
      "source": [
        "def rle_encode(mask):\n",
        "    pixels = mask.flatten()\n",
        "    pixels[0] = 0\n",
        "    pixels[-1] = 0\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
        "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
        "    return runs"
      ],
      "id": "f75d84c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4341ca24"
      },
      "source": [
        "imageio.imread(path).shape[0]"
      ],
      "id": "4341ca24"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "056198d6"
      },
      "outputs": [],
      "source": [
        "with open('submit.txt', 'w') as dst:\n",
        "    dst.write('ImageId,EncodedPixels\\n')\n",
        "    for path in test_paths:\n",
        "        img = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))])\n",
        "        pred_mask = model.predict(img)[0]\n",
        "        bin_mask = 255. * cv2.resize(pred_mask, (imageio.imread(path).shape[0], imageio.imread(path).shape[1]))\n",
        "        bin_mask[bin_mask<=127] = 0\n",
        "        bin_mask[bin_mask>127] = 1\n",
        "        rle = rle_encode(bin_mask.astype(np.uint8))\n",
        "        rle = ' '.join(str(x) for x in rle)\n",
        "        dst.write('%s,%s\\n' % (path.split('/')[-1].split('.')[0], rle))"
      ],
      "id": "056198d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04ec3de5"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('submit.txt', 'r') as in_file:\n",
        "    stripped = (line.strip() for line in in_file)\n",
        "    lines = (line.split(\",\") for line in stripped if line)\n",
        "    with open('submission.csv', 'w') as out_file:\n",
        "        writer = csv.writer(out_file)\n",
        "        writer.writerows(lines)"
      ],
      "id": "04ec3de5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c8ce7fc"
      },
      "outputs": [],
      "source": [],
      "id": "0c8ce7fc"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 298.433932,
      "end_time": "2021-12-17T15:28:41.835666",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-12-17T15:23:43.401734",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}