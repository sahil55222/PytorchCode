{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c8be0c8a",
      "metadata": {
        "id": "c8be0c8a"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-si76NsI7Fs",
        "outputId": "ce3529ba-62af-42c1-f49b-e0bc2a7f2e6f"
      },
      "id": "K-si76NsI7Fs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1ff8d8",
      "metadata": {
        "id": "bc1ff8d8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d46385b",
      "metadata": {
        "id": "4d46385b"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec55567",
      "metadata": {
        "id": "2ec55567"
      },
      "outputs": [],
      "source": [
        "MODULE_URL = \"https://tfhub.dev/google/bit/m-r50x3/1\"\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "SZ = 224\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "NB_CLASSES = 23"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESOLUTION = 224\n",
        "PATCH_SIZE = 16\n",
        "NUM_PATCHES = (RESOLUTION // PATCH_SIZE) ** 2\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 192\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 12\n",
        "MLP_UNITS = [\n",
        "    PROJECTION_DIM * 4,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "DROPOUT_RATE = 0.0\n",
        "DROP_PATH_RATE = 0.1\n",
        "\n",
        "# Training\n",
        "NUM_EPOCHS = 20\n",
        "BASE_LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 32\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 23"
      ],
      "metadata": {
        "id": "wisE_QeMKCBF"
      },
      "id": "wisE_QeMKCBF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7b39b885",
      "metadata": {
        "id": "7b39b885"
      },
      "source": [
        "## Data preprocessing and loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c83598e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c83598e",
        "outputId": "9aed0bde-4dc2-4d62-f855-4c434f9b661c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6399 files belonging to 23 classes.\n",
            "Found 2129 files belonging to 23 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "train_data = '/content/drive/MyDrive/data60/trainData/'\n",
        "val_data = '/content/drive/MyDrive/data60/valData/'\n",
        "\n",
        "def create_image_dataset(data_dir, is_training=True):\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        label_mode='categorical',  # Assuming your labels are in one-hot encoded format\n",
        "        batch_size=BATCH_SIZE,\n",
        "        image_size=(RESOLUTION, RESOLUTION),\n",
        "        shuffle=is_training,\n",
        "        seed=123  # Set a seed for reproducibility\n",
        "    )\n",
        "\n",
        "    if is_training:\n",
        "        num_samples = len(dataset)\n",
        "        # Calculate the number of samples for validation\n",
        "        num_val_samples = int(0.2 * num_samples)  # You can adjust the validation split ratio\n",
        "\n",
        "        # Split the dataset into training and validation sets\n",
        "        dataset = dataset.skip(num_val_samples) if num_val_samples > 0 else dataset\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_image_dataset(train_data, is_training=True)\n",
        "val_dataset = create_image_dataset(val_data, is_training=False)\n",
        "\n",
        "def preprocess_dataset(image, label, is_training=True):\n",
        "    # Standardize the image data (mean=0, std=1)\n",
        "    image = (image - 127.5) / 127.5\n",
        "\n",
        "    if is_training:\n",
        "        # Data augmentation for the training dataset\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        # Add more data augmentation techniques as needed\n",
        "\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing function to both datasets\n",
        "train_dataset = train_dataset.map(lambda x, y: preprocess_dataset(x, y, is_training=True), num_parallel_calls=AUTO)\n",
        "val_dataset = val_dataset.map(lambda x, y: preprocess_dataset(x, y, is_training=False), num_parallel_calls=AUTO)\n",
        "\n",
        "# Use AUTOTUNE for better performance\n",
        "train_dataset = train_dataset.prefetch(AUTO)\n",
        "val_dataset = val_dataset.prefetch(AUTO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969e65eb",
      "metadata": {
        "id": "969e65eb"
      },
      "source": [
        "## Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60bc5d85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60bc5d85",
        "outputId": "4231a877-2efd-4e4c-b4c3-2ef2144b143c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters (millions): 211.315415.\n"
          ]
        }
      ],
      "source": [
        "hub_module = hub.KerasLayer(MODULE_URL)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input((SZ, SZ, 3)),\n",
        "        keras.layers.Rescaling(scale=1.0 / 255),\n",
        "        hub_module,\n",
        "        keras.layers.Dense(NB_CLASSES, kernel_initializer=\"zeros\"),\n",
        "    ],\n",
        "    name=\"bit_teacher_flowers\",\n",
        ")\n",
        "print(f\"Number of parameters (millions): {model.count_params() / 1e6}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee776ae",
      "metadata": {
        "id": "5ee776ae"
      },
      "source": [
        "## Optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3e5526",
      "metadata": {
        "id": "ac3e5526"
      },
      "outputs": [],
      "source": [
        "SCHEDULE_LENGTH = 500\n",
        "SCHEDULE_LENGTH = SCHEDULE_LENGTH * 512 / BATCH_SIZE\n",
        "\n",
        "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
        "lr = 0.003 * BATCH_SIZE / 512\n",
        "\n",
        "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
        "lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=SCHEDULE_BOUNDARIES, values=[lr, lr * 0.1, lr * 0.001, lr * 0.0001]\n",
        ")\n",
        "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01a9c53a",
      "metadata": {
        "id": "01a9c53a"
      },
      "source": [
        "## Train the model and save it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b037387",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b037387",
        "outputId": "e5b39586-b524-4988-cc98-297a09e91106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1017s 66s/step - loss: 2.9593 - accuracy: 0.1312 - val_loss: 2.7422 - val_accuracy: 0.2560\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 99s 11s/step - loss: 2.8069 - accuracy: 0.2156 - val_loss: 2.4803 - val_accuracy: 0.3077\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 91s 10s/step - loss: 2.9168 - accuracy: 0.3000 - val_loss: 3.0485 - val_accuracy: 0.3175\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 73s 8s/step - loss: 2.7037 - accuracy: 0.3594 - val_loss: 2.6108 - val_accuracy: 0.3410\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 91s 10s/step - loss: 2.4574 - accuracy: 0.3406 - val_loss: 2.3823 - val_accuracy: 0.3791\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 73s 8s/step - loss: 2.6039 - accuracy: 0.2781 - val_loss: 2.8818 - val_accuracy: 0.3241\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 91s 10s/step - loss: 2.0638 - accuracy: 0.4219 - val_loss: 2.2600 - val_accuracy: 0.3795\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 91s 10s/step - loss: 2.4237 - accuracy: 0.3750 - val_loss: 1.7603 - val_accuracy: 0.4448\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 73s 8s/step - loss: 1.8771 - accuracy: 0.4406 - val_loss: 2.2255 - val_accuracy: 0.4119\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 72s 8s/step - loss: 2.0445 - accuracy: 0.4000 - val_loss: 2.0702 - val_accuracy: 0.4298\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset.repeat(),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=10,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a27e3ec",
      "metadata": {
        "id": "9a27e3ec"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/hyperKvasir\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862ff7a3",
      "metadata": {
        "id": "862ff7a3"
      },
      "source": [
        "## References\n",
        "\n",
        "* [Official Colab Notebook from BiT authors](https://colab.research.google.com/github/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}