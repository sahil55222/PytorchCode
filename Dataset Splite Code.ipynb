{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c8249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set paths\n",
    "data_dir = 'C:/Users/Sahilur Rahman/Documents/Python Scripts/detrectron2/kvasir-seg/Kvasir-SEG/images/'\n",
    "train_dir = 'C:/Users/Sahilur Rahman/Documents/Python Scripts/detrectron2/kvasir/train'\n",
    "val_dir = 'C:/Users/Sahilur Rahman/Documents/Python Scripts/detrectron2/kvasir/val'  # Directory for validation data\n",
    "test_dir = '\"C:/Users/Sahilur Rahman/Documents/Python Scripts/detrectron2/kvasir/test'\n",
    "\n",
    "# Set split ratios\n",
    "train_ratio = 0.8  # 70% for training\n",
    "val_ratio = 0.10  # 15% for validation\n",
    "test_ratio = 0.10  # 15% for testing\n",
    "\n",
    "# Iterate over each class folder in the data directory\n",
    "for class_folder in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Create class directories in trainDir, valDir, and testDir if they don't exist\n",
    "    train_class_dir = os.path.join(train_dir, class_folder)\n",
    "    val_class_dir = os.path.join(val_dir, class_folder)\n",
    "    test_class_dir = os.path.join(test_dir, class_folder)\n",
    "    for dir_path in [train_class_dir, val_class_dir, test_class_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "    # Get list of file paths for this class\n",
    "    file_paths = [os.path.join(class_path, f) for f in os.listdir(class_path)]\n",
    "    random.shuffle(file_paths)\n",
    "\n",
    "    # Split into training, validation, and testing sets\n",
    "    train_idx = round(len(file_paths) * train_ratio)\n",
    "    val_idx = train_idx + round(len(file_paths) * val_ratio)\n",
    "    train_files = file_paths[:train_idx]\n",
    "    val_files = file_paths[train_idx:val_idx]\n",
    "    test_files = file_paths[val_idx:]\n",
    "\n",
    "    # Move training set files to trainClassDir directory\n",
    "    for file_path in train_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        dest_path = os.path.join(train_class_dir, file_name)\n",
    "        shutil.move(file_path, dest_path)\n",
    "\n",
    "    # Move validation set files to valClassDir directory\n",
    "    for file_path in val_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        dest_path = os.path.join(val_class_dir, file_name)\n",
    "        shutil.move(file_path, dest_path)\n",
    "\n",
    "    # Move testing set files to testClassDir directory\n",
    "    for file_path in test_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        dest_path = os.path.join(test_class_dir, file_name)\n",
    "        shutil.move(file_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f77317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set paths\n",
    "data_dir = \"C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/\"\n",
    "train_dir = 'C:/Users/ungab/OneDrive/Desktop/20x/train/'\n",
    "val_dir = 'C:/Users/ungab/OneDrive/Desktop/20x/valid/'  # Corrected validation directory\n",
    "\n",
    "# Set split ratios\n",
    "train_ratio = 0.7  # 80% for training\n",
    "val_ratio = 0.3  # 20% for validation, corrected ratio\n",
    "\n",
    "# Iterate over each class folder in the data directory\n",
    "for class_folder in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Create class directories in trainDir and valDir if they don't exist\n",
    "    train_class_dir = os.path.join(train_dir, class_folder)\n",
    "    val_class_dir = os.path.join(val_dir, class_folder)\n",
    "    for dir_path in [train_class_dir, val_class_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)  # Use exist_ok to avoid errors if the directory already exists\n",
    "\n",
    "    # Get list of file paths for this class\n",
    "    file_paths = [os.path.join(class_path, f) for f in os.listdir(class_path)]\n",
    "    random.shuffle(file_paths)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    train_idx = round(len(file_paths) * train_ratio)\n",
    "    train_files = file_paths[:train_idx]\n",
    "    val_files = file_paths[train_idx:]\n",
    "\n",
    "    # Move training set files to trainClassDir directory\n",
    "    for file_path in train_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        dest_path = os.path.join(train_class_dir, file_name)\n",
    "        shutil.move(file_path, dest_path)\n",
    "\n",
    "    # Move validation set files to valClassDir directory\n",
    "    for file_path in val_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        dest_path = os.path.join(val_class_dir, file_name)\n",
    "        shutil.move(file_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5ac631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting Augmentor\n",
      "  Downloading Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.65.0)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Augmentor) (9.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Augmentor) (1.24.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ungab\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: Augmentor\n",
      "Successfully installed Augmentor-0.2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install Augmentor tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e306cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Random Images:   0%|          | 0/922 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Random Images: 100%|██████████| 922/922 [00:06<00:00, 147.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 922 image(s) found.\n",
      "Output directory set to C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/augmented_images\\blue."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=512x512 at 0x2673834B4D0>: 100%|██████████| 5/5 [00:00<00:00, 29.54 Samples/s]\n",
      "Copying Random Images: 100%|██████████| 633/633 [00:04<00:00, 137.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 633 image(s) found.\n",
      "Output directory set to C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/augmented_images\\green."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=512x512 at 0x267384FA810>: 100%|██████████| 5/5 [00:00<00:00, 26.83 Samples/s]\n",
      "Copying Random Images: 100%|██████████| 807/807 [00:05<00:00, 138.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 807 image(s) found.\n",
      "Output directory set to C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/augmented_images\\pink."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=512x512 at 0x267383AC090>: 100%|██████████| 5/5 [00:00<00:00, 33.15 Samples/s]\n",
      "Copying Random Images: 100%|██████████| 710/710 [00:04<00:00, 145.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 710 image(s) found.\n",
      "Output directory set to C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/augmented_images\\yellow."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=512x512 at 0x267383A9F90>: 100%|██████████| 5/5 [00:00<00:00, 27.01 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import Augmentor\n",
    "\n",
    "def copy_random_images(src_path, dest_path, num_images):\n",
    "    all_images = os.listdir(src_path)\n",
    "\n",
    "    # Ensure not to sample more images than available\n",
    "    num_images = min(num_images, len(all_images))\n",
    "\n",
    "    random_images = random.sample(all_images, num_images)\n",
    "\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    for img in tqdm(random_images, desc=\"Copying Random Images\"):\n",
    "        src_img_path = os.path.join(src_path, img)\n",
    "        dest_img_path = os.path.join(dest_path, img)\n",
    "        copyfile(src_img_path, dest_img_path)\n",
    "\n",
    "\n",
    "def augment_dataset(src_path, dest_path, num_augmented_per_image):\n",
    "    pipeline = Augmentor.Pipeline(source_directory=src_path, output_directory=dest_path)\n",
    "\n",
    "    # Define augmentation operations as needed\n",
    "    pipeline.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    pipeline.flip_left_right(probability=0.5)\n",
    "    pipeline.zoom_random(probability=0.5, percentage_area=0.8)\n",
    "    pipeline.flip_top_bottom(probability=0.5)\n",
    "\n",
    "    # Execute augmentation\n",
    "    pipeline.sample(num_augmented_per_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your dataset path and output path\n",
    "    dataset_path = \"C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/\"\n",
    "    output_path = \"C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work\\Work1 4 class Classification/Tumor Cellularity Dataset/aug_train/\"\n",
    "\n",
    "    # Set the number of random images to copy per class\n",
    "    num_random_images_per_class = 1000\n",
    "\n",
    "    # Set the number of augmented images to generate per original image\n",
    "    num_augmented_per_image = 5\n",
    "\n",
    "    # Iterate over each class folder in the dataset\n",
    "    for class_folder in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_folder)\n",
    "\n",
    "        # Copy random images from each class\n",
    "        random_images_dest_path = os.path.join(output_path, \"random_images\", class_folder)\n",
    "        copy_random_images(class_path, random_images_dest_path, num_random_images_per_class)\n",
    "\n",
    "        # Apply augmentation on the original dataset\n",
    "        augmented_images_dest_path = os.path.join(output_path, \"augmented_images\", class_folder)\n",
    "        augment_dataset(class_path, augmented_images_dest_path, num_augmented_per_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac8fa84",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Loop to create additional images for this class folder\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_augmented_images_needed):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Randomly select an image from the class folder\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     random_image \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_folder_path, random_image)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Open the image and convert it to a NumPy array\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\random.py:373\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Set the path to the folder containing your original images\n",
    "input_folder = \"C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work/Tumor Bed Selection Dataset/\"\n",
    "\n",
    "# Set the path to the folder where augmented images will be saved\n",
    "output_folder = \"C:/Users/ungab/OneDrive/Desktop/Shakhawat Sir's Work/Tumor Bed Selection Dataset/aug_train/\"\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "augmentation_pipeline = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),  # horizontally flip 50% of the images\n",
    "    iaa.Affine(rotate=(-45, 45)),\n",
    "        # rotate images by -45 to 45 degrees\n",
    "])\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each class folder\n",
    "for class_folder in os.listdir(input_folder):\n",
    "    class_folder_path = os.path.join(input_folder, class_folder)\n",
    "    # Check if the item in the folder is a subdirectory\n",
    "    if os.path.isdir(class_folder_path):\n",
    "        output_class_folder_path = os.path.join(output_folder, class_folder)\n",
    "        # Create the output subfolder for the class if it doesn't exist\n",
    "        if not os.path.exists(output_class_folder_path):\n",
    "            os.makedirs(output_class_folder_path)\n",
    "        # Get the list of images in the class folder\n",
    "        image_files = [file for file in os.listdir(class_folder_path) if file.endswith(\".jpg\") or file.endswith(\".png\")]\n",
    "        # Determine the number of images to be created for this class folder\n",
    "        num_original_images = len(image_files)\n",
    "        num_augmented_images_needed = max(3500 - num_original_images, 0)  # Ensure the minimum is 0\n",
    "        num_augmented_images_needed = min(num_augmented_images_needed, 3500)  # Ensure the maximum is 1000\n",
    "        # Loop to create additional images for this class folder\n",
    "        for i in range(num_augmented_images_needed):\n",
    "            # Randomly select an image from the class folder\n",
    "            random_image = random.choice(image_files)\n",
    "            image_path = os.path.join(class_folder_path, random_image)\n",
    "            # Open the image and convert it to a NumPy array\n",
    "            image = np.array(Image.open(image_path))\n",
    "            # Apply augmentation to create an additional image\n",
    "            augmented_image = augmentation_pipeline(images=[image])[0]\n",
    "            # Convert the augmented NumPy array back to PIL Image\n",
    "            augmented_image = Image.fromarray(augmented_image)\n",
    "            # Save the augmented image to the output folder\n",
    "            output_image_path = os.path.join(output_class_folder_path, f\"augmented_{i}_{random_image}\")\n",
    "            augmented_image.save(output_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
