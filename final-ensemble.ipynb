{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from torchvision import datasets\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from xgboost import XGBClassifier\n","\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","# Step 1: Define your custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, data, targets, transform=None):\n","        self.data = data\n","        self.targets = targets\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data[idx]\n","        target = self.targets[idx]\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample, target\n","\n","seed = 12\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","# Step 2: Define transformations for your custom dataset\n","transform = T.Compose([\n","        T.RandomHorizontalFlip(),\n","        T.RandomVerticalFlip(),\n","        T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.10),\n","        T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.8, 1.2), shear=(-10, 10)),\n","        T.Resize(256),\n","        T.CenterCrop(224),\n","        T.ToTensor(),\n","        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","test_transform = T.Compose([\n","        T.Resize(256),\n","        T.CenterCrop(224),\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","\n","# Step 3: Define function to get data loaders for train, validation, and test datasets\n","def get_data_loaders(data_dir, test_dir, batch_size):\n","    train_data = datasets.ImageFolder(os.path.join(data_dir), transform=transform)\n","    test_data = datasets.ImageFolder(os.path.join(test_dir), transform=test_transform)\n","\n","    train_size = int(0.8 * len(train_data))\n","    val_size = len(train_data) - train_size\n","    train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    return train_loader, val_loader, test_loader\n","\n","import timm\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# Step 4: Load pre-trained PyTorch models\n","model1 = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\n","model2 = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\n","model3 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n","model4 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n","model5 = timm.create_model('mobilenetv2_140', pretrained=True)\n","model6 = timm.create_model('efficientnet_b5', pretrained=True)\n","\n","# Modify the models for binary classification\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","\n","# Assuming 'model' is your existing model\n","# Freeze all parameters in the existing model\n","for param in model1.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model1.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model1.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model1 = model1.to(device)\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","\n","# Assuming 'model' is your existing model\n","# Freeze all parameters in the existing model\n","for param in model2.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model2.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model2.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model2 = model2.to(device)\n","\n","\n","\n","for param in model3.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model3.fc.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model3.fc = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model3 = model3.to(device)\n","\n","for param in model4.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model4.fc.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model4.fc = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model4 = model4.to(device)\n","\n","for param in model5.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model5.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model5.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model5 = model5.to(device)\n","\n","for param in model6.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model6.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model6.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model6 = model6.to(device)\n","\n","# Step 5: Load pre-trained PyTorch models\n","model1_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_DenseNet169.pth\"\n","model2_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_DenseNet201.pth\"\n","model3_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_ResNet101.pth\"\n","model4_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_ResNet152.pth\"\n","model5_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_MobileNetV2.pth\"\n","model6_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_EfficientNet.pth\"\n","\n","\n","\n","model1.load_state_dict(torch.load(model1_path))\n","model2.load_state_dict(torch.load(model2_path))\n","model3.load_state_dict(torch.load(model3_path))\n","model4.load_state_dict(torch.load(model4_path))\n","model5.load_state_dict(torch.load(model5_path))\n","model6.load_state_dict(torch.load(model6_path))\n","\n","\n","# Set models to evaluation mode\n","model1.eval()\n","model2.eval()\n","model3.eval()\n","model4.eval()\n","model5.eval()\n","model6.eval()\n","\n","# Step 6: Make predictions using the pre-trained models\n","def get_predictions(model, dataloader):\n","    all_predictions = []\n","    with torch.no_grad():\n","        for inputs, targets in dataloader:\n","            inputs = inputs.to(device)  # Move inputs to the appropriate device\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            all_predictions.extend(predicted.cpu().numpy())  # Convert to numpy array for stacking\n","    return all_predictions\n","\n","# Step 7: Stack the predictions for meta-model training\n","train_loader, val_loader, test_loader = get_data_loaders(\"/kaggle/input/bavumub-shortwork/trainFinal/\", \"/kaggle/input/augmented-20x-10x/20x/20x/test\", batch_size=128)\n","\n","# Get predictions for training and validation sets\n","predictions_model1_train = get_predictions(model1, train_loader)\n","predictions_model2_train = get_predictions(model2, train_loader)\n","predictions_model3_train = get_predictions(model3, train_loader)\n","predictions_model4_train = get_predictions(model4, train_loader)\n","predictions_model5_train = get_predictions(model5, train_loader)\n","predictions_model6_train = get_predictions(model6, train_loader)\n","\n","stacked_predictions_train = np.column_stack((predictions_model1_train, predictions_model2_train, predictions_model3_train,predictions_model4_train,predictions_model5_train,predictions_model6_train))\n","\n","# Get predictions for validation set for training the meta-model\n","predictions_model1_val = get_predictions(model1, val_loader)\n","predictions_model2_val = get_predictions(model2, val_loader)\n","predictions_model3_val = get_predictions(model3, val_loader)\n","predictions_model4_val = get_predictions(model4, val_loader)\n","predictions_model5_val = get_predictions(model5, val_loader)\n","predictions_model6_val = get_predictions(model6, val_loader)\n","\n","\n","stacked_predictions_val = np.column_stack((predictions_model1_val, predictions_model2_val, predictions_model3_val, predictions_model4_val, predictions_model5_val,predictions_model6_val))\n","\n","# Extract labels for the validation set\n","val_labels = []\n","for _, target in val_loader.dataset:\n","    val_labels.append(target)\n","val_labels = np.array(val_labels)\n","\n","# Train the logistic regression meta-model\n","#meta_model = SVC() \n","#meta_model = GradientBoostingClassifier() \n","meta_model = DecisionTreeClassifier()\n","#meta_model = LogisticRegression(random_state=45), \n","#meta_model = KNeighborsClassifier() \n","#meta_model = AdaBoostClassifier() \n","#meta_model = XGBClassifier()\n","#meta_model = GaussianNB() \n","#meta_model = GradientBoostingClassifier()  \n","#meta_model = RandomForestClassifier()\n","meta_model.fit(stacked_predictions_val, val_labels)\n","\n","# Step 9: Make predictions on the test dataset\n","test_predictions_model1 = get_predictions(model1, test_loader)\n","test_predictions_model2 = get_predictions(model2, test_loader)\n","test_predictions_model3 = get_predictions(model3, test_loader)\n","test_predictions_model4 = get_predictions(model4, test_loader)\n","test_predictions_model5 = get_predictions(model5, test_loader)\n","test_predictions_model6 = get_predictions(model6, test_loader)\n","\n","\n","test_stacked_predictions = np.column_stack((test_predictions_model1, test_predictions_model2, test_predictions_model3, test_predictions_model4, test_predictions_model5,test_predictions_model6))\n","\n","# Extract labels for the test set\n","test_labels = []\n","for _, target in test_loader.dataset:\n","    test_labels.append(target)\n","test_labels = np.array(test_labels)\n","\n","# Step 10: Use the meta-model to make predictions on the stacked test predictions\n","test_meta_preds = meta_model.predict(test_stacked_predictions)\n","\n","# Step 11: Evaluate the accuracy of the stacked ensemble model\n","ensemble_accuracy = accuracy_score(test_labels, test_meta_preds)\n","print(\"Stacked Ensemble Accuracy:\", ensemble_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Hybrid CNN ELM Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from torchvision import datasets\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import timm\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class ELMClassifier:\n","    def __init__(self, n_hidden_units=100, n_output_neurons=2):\n","        self.n_hidden_units = n_hidden_units\n","        self.n_output_neurons = n_output_neurons\n","\n","    def fit(self, X, y):\n","        # Normalize features to be in the range [-1, 1]\n","        X = 2 * (X - np.min(X)) / (np.max(X) - np.min(X)) - 1\n","\n","        self.input_weights = np.random.normal(size=(X.shape[1], self.n_hidden_units))\n","        self.bias = np.random.normal(size=(self.n_hidden_units,))\n","        hidden_activations = np.dot(X, self.input_weights) + self.bias\n","\n","        # Moore-Penrose pseudo-inverse to calculate output weights\n","        self.output_weights = np.linalg.pinv(hidden_activations).dot(y)\n","\n","    def predict(self, X):\n","        # Normalize features to be in the range [-1, 1]\n","        X = 2 * (X - np.min(X)) / (np.max(X) - np.min(X)) - 1\n","\n","        hidden_activations = np.dot(X, self.input_weights) + self.bias\n","        output = np.dot(hidden_activations, self.output_weights)\n","        return np.argmax(output, axis=1)\n","\n","# Set random seed for reproducibility\n","seed = 12\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","# Define transformations for your custom dataset\n","transform = T.Compose([\n","    T.RandomHorizontalFlip(),\n","    T.RandomVerticalFlip(),\n","    T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.10),\n","    T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.8, 1.2), shear=(-10, 10)),\n","    T.Resize(256),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","test_transform = T.Compose([\n","    T.Resize(256),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","# Define function to get data loaders for train, validation, and test datasets\n","def get_data_loaders(data_dir, test_dir, batch_size):\n","    train_data = datasets.ImageFolder(os.path.join(data_dir), transform=transform)\n","    test_data = datasets.ImageFolder(os.path.join(test_dir), transform=test_transform)\n","\n","    train_size = int(0.8 * len(train_data))\n","    val_size = len(train_data) - train_size\n","    train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    return train_loader, val_loader, test_loader\n","\n","# Load pre-trained PyTorch models\n","model1 = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\n","model2 = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\n","model3 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n","model4 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n","model5 = timm.create_model('mobilenetv2_140', pretrained=True)\n","model6 = timm.create_model('efficientnet_b5', pretrained=True)\n","\n","# Modify the models for binary classification\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","\n","# Assuming 'model' is your existing model\n","# Freeze all parameters in the existing model\n","for param in model1.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model1.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model1.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model1 = model1.to(device)\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","\n","# Assuming 'model' is your existing model\n","# Freeze all parameters in the existing model\n","for param in model2.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model2.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model2.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model2 = model2.to(device)\n","\n","\n","\n","for param in model3.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model3.fc.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model3.fc = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model3 = model3.to(device)\n","\n","for param in model4.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model4.fc.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model4.fc = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model4 = model4.to(device)\n","\n","for param in model5.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model5.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model5.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model5 = model5.to(device)\n","\n","for param in model6.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model6.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model6.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model6 = model6.to(device)\n","\n","# Step 5: Load pre-trained PyTorch models\n","model1_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_DenseNet169.pth\"\n","model2_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_DenseNet201.pth\"\n","model3_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_ResNet101.pth\"\n","model4_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_ResNet152.pth\"\n","model5_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_MobileNetV2.pth\"\n","model6_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_EfficientNet.pth\"\n","\n","\n","\n","model1.load_state_dict(torch.load(model1_path))\n","model2.load_state_dict(torch.load(model2_path))\n","model3.load_state_dict(torch.load(model3_path))\n","model4.load_state_dict(torch.load(model4_path))\n","model5.load_state_dict(torch.load(model5_path))\n","model6.load_state_dict(torch.load(model6_path))\n","\n","\n","# Set models to evaluation mode\n","model1.eval()\n","model2.eval()\n","model3.eval()\n","model4.eval()\n","model5.eval()\n","model6.eval()\n","\n","# Get data loaders\n","train_loader, val_loader, test_loader = get_data_loaders(\"/kaggle/input/bavumub-shortwork/trainFinal/\", \"/kaggle/input/augmented-20x-10x/20x/20x/test\", batch_size=128)\n","\n","# Extract Convolutional Features Function\n","def extract_conv_features(model, dataloader):\n","    model.eval()\n","    features_list = []\n","    with torch.no_grad():\n","        for images, _ in dataloader:\n","            images = images.to(device)\n","            features = model(images).detach().cpu().numpy()\n","            features_list.append(features.reshape(features.shape[0], -1))\n","    return np.concatenate(features_list)\n","\n","# Extract convolutional features from models\n","conv_features1 = extract_conv_features(model1, train_loader)\n","conv_features2 = extract_conv_features(model2, train_loader)\n","conv_features3 = extract_conv_features(model3, train_loader)\n","conv_features4 = extract_conv_features(model4, train_loader)\n","conv_features5 = extract_conv_features(model5, train_loader)\n","conv_features6 = extract_conv_features(model6, train_loader)\n","\n","# Apply ELM on convolutional features\n","elm_models = [ELMClassifier() for _ in range(6)]\n","for elm_model, conv_features in zip(elm_models, [conv_features1, conv_features2, conv_features3, conv_features4, conv_features5, conv_features6]):\n","    elm_model.fit(conv_features, np.concatenate(all_targets))\n","\n","# Get ground truth labels and make predictions using each ELM model\n","val_targets = []\n","elm_val_predictions = []\n","\n","for images, targets in val_loader:\n","    images = images.to(device)\n","    targets = targets.numpy()\n","    val_targets.extend(targets)\n","\n","    # Make predictions using each ELM model\n","    elm_model_predictions = []\n","    for elm_model, model in zip(elm_models, [model1, model2, model3, model4, model5, model6]):\n","        all_outputs = []\n","        with torch.no_grad():\n","            outputs = model(images).detach().cpu().numpy()\n","            all_outputs.append(outputs.reshape(outputs.shape[0], -1))\n","\n","        predictions = elm_model.predict(np.concatenate(all_outputs))\n","        elm_model_predictions.append(predictions)\n","\n","    elm_val_predictions.append(majority_voting(elm_model_predictions))\n","\n","# Flatten the list of predictions\n","elm_majority_voting_val_predictions = [item for sublist in elm_val_predictions for item in sublist]\n","\n","# Combine predictions using majority voting\n","def majority_voting(predictions_list):\n","    final_predictions = []\n","    for i in range(len(predictions_list[0])):\n","        preds = [predictions[i] for predictions in predictions_list]\n","        final_predictions.append(np.bincount(preds).argmax())\n","    return final_predictions\n","\n","# Calculate accuracy\n","elm_val_accuracy = accuracy_score(val_targets, elm_majority_voting_val_predictions)\n","print(\"ELM ensemble validation accuracy:\", elm_val_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Dataset, random_split\n","from torchvision import datasets\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","import numpy as np\n","\n","class ELMClassifier:\n","    def __init__(self, n_hidden_units=100, n_output_neurons=2):\n","        self.n_hidden_units = n_hidden_units\n","        self.n_output_neurons = n_output_neurons\n","\n","    def fit(self, X, y):\n","        # Normalize features to be in the range [-1, 1]\n","        X = 2 * (X - np.min(X)) / (np.max(X) - np.min(X)) - 1\n","\n","        self.input_weights = np.random.normal(size=(X.shape[1], self.n_hidden_units))\n","        self.bias = np.random.normal(size=(self.n_hidden_units,))\n","        hidden_activations = np.dot(X, self.input_weights) + self.bias\n","\n","        # Moore-Penrose pseudo-inverse to calculate output weights\n","        self.output_weights = np.linalg.pinv(hidden_activations).dot(y)\n","\n","    def predict(self, X):\n","        # Normalize features to be in the range [-1, 1]\n","        X = 2 * (X - np.min(X)) / (np.max(X) - np.min(X)) - 1\n","\n","        hidden_activations = np.dot(X, self.input_weights) + self.bias\n","        output = np.dot(hidden_activations, self.output_weights)\n","        return np.argmax(output, axis=1)\n","\n","# Set random seed for reproducibility\n","seed = 12\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","# Define transformations for custom dataset\n","transform = T.Compose([\n","    T.RandomHorizontalFlip(),\n","    T.RandomVerticalFlip(),\n","    T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.10),\n","    T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.8, 1.2), shear=(-10, 10)),\n","    T.Resize(256),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","test_transform = T.Compose([\n","    T.Resize(256),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","# Define function to get data loaders for train, validation, and test datasets\n","def get_data_loaders(data_dir, test_dir, batch_size):\n","    train_data = datasets.ImageFolder(os.path.join(data_dir), transform=transform)\n","    test_data = datasets.ImageFolder(os.path.join(test_dir), transform=test_transform)\n","\n","    train_size = int(0.8 * len(train_data))\n","    val_size = len(train_data) - train_size\n","    train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    return train_loader, val_loader, test_loader\n","\n","import timm\n","# Load pre-trained PyTorch models\n","#model1 = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\n","model2 = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\n","model3 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n","model4 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","\n","# Assuming 'model' is your existing model\n","# Freeze all parameters in the existing model\n","for param in model2.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model2.classifier.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model2.classifier = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model2 = model2.to(device)\n","\n","for param in model3.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model3.fc.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model3.fc = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model3 = model3.to(device)\n","\n","for param in model4.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features of the existing fc layer\n","n_inputs = model4.fc.in_features\n","\n","# Modify the fc layer and add more layers for reducing val loss\n","model4.fc = nn.Sequential(\n","    nn.Linear(n_inputs, 1024),\n","    nn.BatchNorm1d(1024),  # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(1024, 512),\n","    nn.BatchNorm1d(512),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 256),\n","    nn.BatchNorm1d(256),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(256, 128),\n","    nn.BatchNorm1d(128),   # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(128, 64),\n","    nn.BatchNorm1d(64),    # Batch Normalization\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(64, 2),\n","    nn.Softmax(dim=1)  # Softmax activation function\n",")\n","\n","model4 = model4.to(device)\n","\n","# Step 5: Load pre-trained PyTorch models\n","#model1_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_DenseNet169.pth\"\n","model2_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_DenseNet201.pth\"\n","model3_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_ResNet101.pth\"\n","model4_path = \"/kaggle/input/cnn-bvm/CNN_Models/PTH/model_ResNet152.pth\"\n","\n","#model1.load_state_dict(torch.load(model1_path))\n","model2.load_state_dict(torch.load(model2_path))\n","model3.load_state_dict(torch.load(model3_path))\n","model4.load_state_dict(torch.load(model4_path))\n","\n","# Set models to evaluation mode\n","#model1.eval()\n","model2.eval()\n","model3.eval()\n","model4.eval()\n","\n","# Get data loaders\n","train_loader, val_loader, test_loader = get_data_loaders(\"/kaggle/input/bavumub-shortwork/trainFinal/\", \"/kaggle/input/augmented-20x-10x/20x/20x/test\", batch_size=128)\n","# Apply ELM on each model's outputs\n","elm_models = [ELMClassifier() for _ in range(3)]\n","\n","# Calculate the total train size using train_loader instead of train_dataset\n","total_train_size = len(train_loader.dataset)\n","split_size = total_train_size // 4\n","\n","# Define start and end indices for each part\n","start_indices = [i * split_size for i in range(4)]\n","end_indices = [(i + 1) * split_size for i in range(4)]\n","end_indices[-1] = total_train_size  # Adjust the last end index\n","\n","for elm_model, model, start_idx, end_idx in zip(elm_models, [model2, model3, model4], start_indices, end_indices):\n","    model.to(device)\n","    model.eval()\n","\n","    # Create a data loader for the current model's portion of the dataset\n","    train_subset = torch.utils.data.Subset(train_loader.dataset, list(range(start_idx, end_idx)))\n","    train_loader_model = DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=4)\n","\n","    all_outputs = []\n","    all_targets = []\n","\n","    for images, targets in train_loader_model:\n","        images = images.to(device)\n","        targets = targets.to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(images)\n","            all_outputs.append(outputs.detach().cpu().numpy().reshape(outputs.shape[0], -1))\n","            all_targets.append(targets.cpu().numpy().reshape(-1, 1))\n","\n","    # Fit ELM with the outputs from the current model's data loader\n","    elm_model.fit(np.concatenate(all_outputs),\n","                  np.concatenate(all_targets))\n","\n","# Get ground truth labels for validation set\n","val_targets = []\n","for _, targets in test_loader:\n","    val_targets.extend(targets.numpy())\n","\n","# Make predictions using each ELM model\n","elm_val_predictions = []\n","for elm_model, model in zip(elm_models, [model2, model3, model4]):\n","    all_outputs = []\n","    for images, _ in test_loader:\n","        images = images.to(device)\n","        with torch.no_grad():\n","            outputs = model(images).detach().cpu().numpy()\n","            all_outputs.append(outputs.reshape(outputs.shape[0], -1))\n","\n","    predictions = elm_model.predict(np.concatenate(all_outputs))\n","    elm_val_predictions.append(predictions)\n","\n","# Combine predictions using majority voting\n","def majority_voting(predictions_list):\n","    final_predictions = []\n","    for preds in zip(*predictions_list):\n","        final_predictions.append(max(set(preds), key=preds.count))\n","    return final_predictions\n","\n","elm_majority_voting_val_predictions = majority_voting(elm_val_predictions)\n","\n","# Calculate accuracy\n","elm_val_accuracy = accuracy_score(val_targets, elm_majority_voting_val_predictions)\n","print(\"ELM ensemble validation accuracy:\", elm_val_accuracy)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4460164,"sourceId":7650840,"sourceType":"datasetVersion"},{"datasetId":4532744,"sourceId":7752516,"sourceType":"datasetVersion"},{"datasetId":4535401,"sourceId":7756197,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
